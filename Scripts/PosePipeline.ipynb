{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7030219d-13a3-4037-a21e-52be4c5dc7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# only use the first GPU if there are multiple\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# limit jax and TF from consuming all GPU memory\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "\n",
    "# List available GPUs in TensorFlow\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# load metrab model \n",
    "model = hub.load('https://bit.ly/metrabs_l')  # Takes about 3 minutes\n",
    "skeleton = 'mpi_inf_3dhp_17'\n",
    "\n",
    "# load gait transformer model \n",
    "from gait_transformer.gait_phase_transformer import load_default_model, get_gait_phase_stride_transformer, gait_phase_stride_inference\n",
    "from gait_transformer.gait_phase_kalman import gait_kalman_smoother, compute_phases, get_event_times\n",
    "from tensorflow import keras\n",
    "\n",
    "pos_divider = 2\n",
    "transformer_model = load_default_model(pos_divider=pos_divider)\n",
    "\n",
    "# change joint order \n",
    "joint_names = np.array(['htop', 'neck', 'rsho', 'relb', 'rwri', 'lsho', 'lelb', 'lwri',\n",
    "       'rhip', 'rkne', 'rank', 'lhip', 'lkne', 'lank', 'pelv', 'spin',\n",
    "       'head'])\n",
    "# this is the order of joints from the Gast-NET algorithm that the gait transformer was originally trained on\n",
    "expected_order = ['pelv', 'rhip', 'rkne', 'rank', 'lhip', 'lkne', 'lank', 'spin', 'neck', 'head', 'htop', 'lsho', 'lelb', 'lwri', 'rsho', 'relb', 'rwri']\n",
    "expected_order_idx = np.array([joint_names.tolist().index(j) for j in expected_order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5c5e1f4-8cc3-43f3-b75f-8b4cf1300792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert values to integers\n",
    "def convert_to_int(data):\n",
    "    int_data = {}\n",
    "    for key, values in data.items():\n",
    "        int_data[key] = [int(value) for value in values]\n",
    "    return int_data\n",
    "\n",
    "# def extract_parts(filename):\n",
    "#     match = re.match(r'(Diz|Val)_(\\d+)_(?:CT|T)(\\d+)', filename)\n",
    "#     if match:\n",
    "#         prefix = match.group(1)\n",
    "#         part1 = int(match.group(2))\n",
    "#         part2 = int(match.group(3))\n",
    "#         # Use a sorting key that puts \"Diz\" (which is 0) before \"Val\" (which is 1)\n",
    "#         prefix_order = 0 if prefix == \"Diz\" else 1\n",
    "#         return (prefix_order, part1, part2)\n",
    "#     return (float('inf'), float('inf'), float('inf'))  # Unmatched files last\n",
    "\n",
    "\n",
    "def extract_parts(filename):\n",
    "    match = re.match(r'(GEN)_(\\d+)_(?:CT|T)(\\d+)', filename)\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        part1 = int(match.group(2))\n",
    "        part2 = int(match.group(3))\n",
    "        # Use a sorting key that puts \"Diz\" (which is 0) before \"Val\" (which is 1)\n",
    "        prefix_order = 0 if prefix == \"Diz\" else 1\n",
    "        return (prefix_order, part1, part2)\n",
    "    return (float('inf'), float('inf'), float('inf'))  # Unmatched files last\n",
    "\n",
    "\n",
    "# read video and get keypoints \n",
    "def video_reader(filename: str, batch_size: int = 8, width=320):\n",
    "\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is False:\n",
    "            \n",
    "            if len(frames) > 0:\n",
    "                frames = np.array(frames)\n",
    "                yield frames\n",
    "\n",
    "            cap.release()\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if width is not None:\n",
    "                # downsample to keep the aspect ratio and output the specified width\n",
    "                scale = width / frame.shape[1]\n",
    "                height = int(frame.shape[0] * scale)\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "            \n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) >= batch_size:\n",
    "                frames = np.array(frames)\n",
    "                yield frames\n",
    "                \n",
    "                frames = []\n",
    "\n",
    "    \n",
    "def shift_invalid_rows(data):\n",
    "    # Get the first column values\n",
    "    first_col = data[:, 0]\n",
    "    reference_value = first_col[0]  # First value as reference    # Shift rows where the first column value is greater than the reference value\n",
    "    for i in range(1, len(first_col)):\n",
    "        if first_col[i] > reference_value:\n",
    "            data[i] = np.hstack(([np.nan], data[i, :-1]))    \n",
    "    return data\n",
    "\n",
    "# mirror video function \n",
    "def mirror_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Mirrors a single video horizontally and saves the output.\n",
    "    \n",
    "    Parameters:\n",
    "        input_path (str): Path to the input video file.\n",
    "        output_path (str): Path to save the mirrored video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {input_path}\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        flipped_frame = cv2.flip(frame, 1)\n",
    "        out.write(flipped_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Mirrored video saved as {output_path}\")\n",
    "\n",
    "\n",
    "# pose estimation function \n",
    "def process_video_for_keypoints(\n",
    "    file_name,\n",
    "    directory_path,\n",
    "    output_dir,\n",
    "    model,\n",
    "    skeleton,\n",
    "    video_reader,\n",
    "    processed_files=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a video to extract 3D pose keypoints if exactly one person is detected per frame.\n",
    "    Saves the pose data as a .npy file.\n",
    "\n",
    "    Parameters:\n",
    "        file_name (str): Name of the video file.\n",
    "        directory_path (str): Directory where the input video is located.\n",
    "        output_dir (str): Directory to save the output .npy file.\n",
    "        model: Pose detection model with .detect_poses_batched().\n",
    "        skeleton: Skeleton structure used by the model.\n",
    "        video_reader: Function to read video frames in batches.\n",
    "        processed_files (set): Set of already processed file base names (without extension).\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "    if processed_files and video_name in processed_files:\n",
    "        print(f\"Skipping {file_name} — already processed.\")\n",
    "        return\n",
    "\n",
    "    video_filepath = os.path.join(directory_path, file_name)\n",
    "    vid = video_reader(video_filepath, width=None)\n",
    "\n",
    "    multiple_people_detected = False\n",
    "    nonvalid_pose_detected = False\n",
    "    accumulated = None\n",
    "\n",
    "    for i, frame_batch in tqdm(enumerate(vid), desc=f\"Processing {file_name}\"):\n",
    "        pred = model.detect_poses_batched(frame_batch, skeleton=skeleton)\n",
    "\n",
    "        if accumulated is None:\n",
    "            accumulated = pred\n",
    "        else:\n",
    "            for key in accumulated.keys():\n",
    "                accumulated[key] = tf.concat([accumulated[key], pred[key]], axis=0)\n",
    "\n",
    "        num_people = [p.shape[0] for p in accumulated['poses2d']]\n",
    "\n",
    "        if len(set(num_people)) > 1:\n",
    "            multiple_people_detected = True\n",
    "\n",
    "        if any(n == 0 for n in num_people):\n",
    "            nonvalid_pose_detected = True\n",
    "            break\n",
    "\n",
    "    if multiple_people_detected:\n",
    "        print(f\"2 - {file_name} has multiple people detected.\")\n",
    "        \n",
    "\n",
    "    if nonvalid_pose_detected:\n",
    "        print(f\"Skipping {file_name} — one or more frames have no detected person.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    pose3d = np.array([p[0] for p in accumulated['poses3d']])\n",
    "    output_file_name = f\"{video_name}.npy\"\n",
    "    np.save(os.path.join(output_dir, output_file_name), pose3d)\n",
    "    print(f\"Processed {file_name} and saved keypoints to {output_file_name}\")\n",
    "\n",
    "\n",
    "# gait transformer function \n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from gait_transformer.gait_phase_transformer import gait_phase_stride_inference\n",
    "from gait_transformer.gait_phase_kalman import gait_kalman_smoother, get_event_times\n",
    "\n",
    "def process_gait_keypoints_to_json(\n",
    "    file_path,\n",
    "    output_directory,\n",
    "    transformer_model,\n",
    "    height,\n",
    "    expected_order_idx,\n",
    "    L=60,\n",
    "    pos_divider=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a 3D keypoints .npy file using the gait transformer model and saves gait events to JSON.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the .npy file containing 3D keypoints.\n",
    "        output_directory (str): Directory to save the resulting JSON file.\n",
    "        transformer_model: Loaded gait transformer model.\n",
    "        height (float): Subject height in mm (will be scaled internally).\n",
    "        expected_order_idx (np.array): Indices to reorder joints.\n",
    "        L (int): Window length for inference (default: 60).\n",
    "        pos_divider (int): Positional divider used in model loading (default: 2).\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    keypoints = np.load(file_path)\n",
    "\n",
    "    # Reorder, normalize and transform keypoints\n",
    "    keypoints = keypoints[:, expected_order_idx]\n",
    "    keypoints = keypoints / 1000.0          # mm → m\n",
    "    keypoints = keypoints - np.mean(keypoints, axis=1, keepdims=True)\n",
    "    keypoints = keypoints[:, :, [0, 2, 1]]  # reordering axes\n",
    "    keypoints[:, :, 2] *= -1                # flip z\n",
    "\n",
    "    # Run inference\n",
    "    phase, stride = gait_phase_stride_inference(keypoints, height, transformer_model, L * pos_divider)\n",
    "\n",
    "    # Kalman smoothing\n",
    "    phase_ordered = np.take(phase, [0, 4, 1, 5, 2, 6, 3, 7], axis=-1)\n",
    "    state, _, _ = gait_kalman_smoother(phase_ordered)\n",
    "    timestamps = np.arange(state.shape[0])\n",
    "    gait_event_dic = get_event_times(state, timestamps)\n",
    "\n",
    "    # Save result to JSON\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    output_path = os.path.join(output_directory, file_name.replace('.npy', f'_gait_events_L{L}.json'))\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({k: v.tolist() for k, v in gait_event_dic.items()}, f, indent=4)\n",
    "\n",
    "    print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "\n",
    "# arrange gait events function \n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def arrange_gait_events_to_excel(\n",
    "    directory_path,\n",
    "    output_excel_path,\n",
    "    extract_parts,\n",
    "    convert_to_int,\n",
    "    shift_invalid_rows\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes gait event JSON files, rearranges data, and saves to a structured Excel sheet.\n",
    "\n",
    "    Parameters:\n",
    "        directory_path (str): Directory containing gait event JSON files.\n",
    "        output_excel_path (str): Path to save the final Excel file.\n",
    "        extract_parts (function): Function used to sort files naturally.\n",
    "        convert_to_int (function): Function to convert JSON string data to integers.\n",
    "        shift_invalid_rows (function): Function to clean/adjust invalid data rows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get list of L60 JSON files and sort them\n",
    "    file_names = [f for f in os.listdir(directory_path) if f.endswith('L60.json')]\n",
    "    file_names.sort(key=extract_parts)\n",
    "\n",
    "    dfs = []\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            int_data = convert_to_int(data)\n",
    "            df = pd.DataFrame.from_dict(int_data, orient='index')\n",
    "            dfs.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No dataframes created. Exiting.\")\n",
    "        return\n",
    "\n",
    "    combined_df = pd.concat(dfs)\n",
    "    NUM_T = int(combined_df.shape[0] / 4)\n",
    "\n",
    "    # Add trial names\n",
    "    file_labels = [\"_\".join(f.split(\"_\")[:3]) for f in file_names for _ in range(4)]\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    combined_df.insert(0, 'Trial', file_labels)\n",
    "    combined_df.rename(columns={'index': 'gait_event'}, inplace=True)\n",
    "\n",
    "    # Swap stride_L and stride_R\n",
    "    for k in range(NUM_T):\n",
    "        i1, i2 = 1 + 4 * k, 2 + 4 * k\n",
    "        combined_df.iloc[[i1, i2]] = combined_df.iloc[[i2, i1]].values\n",
    "\n",
    "    # Process data chunks\n",
    "    chunked_data = []\n",
    "    for i in range(0, len(combined_df), 4):\n",
    "        chunk = combined_df.iloc[i:i + 4]\n",
    "        processed = shift_invalid_rows(chunk.values[:, 2:])\n",
    "        chunked_data.append(processed)\n",
    "\n",
    "    final_data = np.vstack(chunked_data)\n",
    "    final_df = pd.DataFrame(np.hstack([combined_df[['Trial', 'gait_event']], final_data]),\n",
    "                            columns=['Trial', 'gait_event'] + combined_df.columns[2:].tolist())\n",
    "\n",
    "    final_df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"Saved arranged gait events to {output_excel_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def run_full_gait_processing_pipeline(\n",
    "    video_directory,\n",
    "    keypoints_output_dir,\n",
    "    gait_json_output_dir,\n",
    "    final_excel_path,\n",
    "    model,\n",
    "    skeleton,\n",
    "    video_reader,\n",
    "    transformer_model,\n",
    "    height_mm,\n",
    "    expected_order_idx,\n",
    "    extract_parts,\n",
    "    convert_to_int,\n",
    "    shift_invalid_rows,\n",
    "    pos_divider=2,\n",
    "    L=60\n",
    "):\n",
    "    import os\n",
    "\n",
    "    # --- STEP 1: Pose Estimation from videos ---\n",
    "    print(\"Step 1: Extracting pose keypoints from video files...\")\n",
    "\n",
    "    # Make sure the keypoints output directory exists\n",
    "    os.makedirs(keypoints_output_dir, exist_ok=True)\n",
    "    \n",
    "    video_files = [f for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    "    video_files.sort(key=extract_parts)\n",
    "    processed_files = {os.path.splitext(f)[0] for f in os.listdir(keypoints_output_dir) if f.endswith('.npy')}\n",
    "\n",
    "    for file_name in video_files:\n",
    "        process_video_for_keypoints(\n",
    "            file_name=file_name,\n",
    "            directory_path=video_directory,\n",
    "            output_dir=keypoints_output_dir,\n",
    "            model=model,\n",
    "            skeleton=skeleton,\n",
    "            video_reader=video_reader,\n",
    "            processed_files=processed_files\n",
    "        )\n",
    "\n",
    "    # --- STEP 2: Run Gait Transformer on keypoints ---\n",
    "    print(\"Step 2: Running Gait Transformer model on extracted keypoints...\")\n",
    "    keypoint_files = sorted(\n",
    "        [f for f in os.listdir(keypoints_output_dir) if f.endswith('.npy')],\n",
    "        key=extract_parts\n",
    "    )\n",
    "\n",
    "    for file_name in keypoint_files:\n",
    "        file_path = os.path.join(keypoints_output_dir, file_name)\n",
    "        process_gait_keypoints_to_json(\n",
    "            file_path=file_path,\n",
    "            output_directory=gait_json_output_dir,\n",
    "            transformer_model=transformer_model,\n",
    "            height=height_mm,\n",
    "            expected_order_idx=expected_order_idx,\n",
    "            L=L,\n",
    "            pos_divider=pos_divider\n",
    "        )\n",
    "\n",
    "    # --- STEP 3: Arrange Gait Events and Save to Excel ---\n",
    "    print(\"Step 3: Arranging gait events and exporting to Excel...\")\n",
    "    arrange_gait_events_to_excel(\n",
    "        directory_path=gait_json_output_dir,\n",
    "        output_excel_path=final_excel_path,\n",
    "        extract_parts=extract_parts,\n",
    "        convert_to_int=convert_to_int,\n",
    "        shift_invalid_rows=shift_invalid_rows\n",
    "    )\n",
    "\n",
    "    print(\"✅ Full gait processing pipeline complete.\")\n",
    "\n",
    "\n",
    "# filter function \n",
    "import pandas as pd\n",
    "def filter_numeric_columns(df: pd.DataFrame, threshold: float = 12) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters numeric columns in a DataFrame by keeping only values >= threshold.\n",
    "    Non-numeric columns are preserved and returned as-is.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with mixed types.\n",
    "        threshold (float): Minimum value to retain in numeric columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with numeric values below threshold set to NaN.\n",
    "    \"\"\"\n",
    "    df_numeric = df.select_dtypes(include='number')\n",
    "    df_filtered = df_numeric.where(df_numeric >= threshold)\n",
    "    df_non_numeric = df.select_dtypes(exclude='number')\n",
    "    df_combined = pd.concat([df_non_numeric, df_filtered], axis=1)\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "# get gait features function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_gait_video_features(\n",
    "    df_video: pd.DataFrame,\n",
    "    keypoints_dir: str,\n",
    "    expected_order_idx: list,\n",
    "    fps: int = 60,\n",
    "    extract_parts=None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze spatiotemporal gait features from gait event timing and 3D keypoints.\n",
    "\n",
    "    Parameters:\n",
    "        df_video (pd.DataFrame): Gait event data organized in 4-row blocks (LHS, LTO, RHS, RTO).\n",
    "        keypoints_dir (str): Directory containing .npy keypoint files.\n",
    "        expected_order_idx (list): Joint reordering index.\n",
    "        fps (int): Frames per second.\n",
    "        output_path (str): Path to save the output Excel file.\n",
    "        extract_parts (function): Function for natural file sorting.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of extracted gait features.\n",
    "    \"\"\"\n",
    "    # Pre-allocate lists\n",
    "    trial_name_list, avg_swing_left_list, avg_swing_right_list = [], [], []\n",
    "    avg_stance_left_list, avg_stance_right_list = [], []\n",
    "    avg_steptime_left_list, avg_steptime_right_list = [], []\n",
    "    avg_step_length_left_list, avg_step_length_right_list = [], []\n",
    "    cadence_list, avg_swing_list, avg_stance_list = [], [], []\n",
    "    avg_double_list, avg_velocity_list, avg_steplength_list = [], [], []\n",
    "    avg_steptime_list, correlation_list = [], []\n",
    "\n",
    "    files = sorted(os.listdir(keypoints_dir), key=extract_parts)\n",
    "    loop = len(df_video)\n",
    "\n",
    "    for m in range(loop // 4):\n",
    "        # Extract gait events\n",
    "        lhs, ltf = df_video.loc[4*m,0:], df_video.loc[4*m+1,0:]\n",
    "        rhs, rtf = df_video.loc[4*m+2,0:], df_video.loc[4*m+3,0:]\n",
    "\n",
    "        # Compute temporal phases\n",
    "        L_swing = (lhs - ltf).dropna()\n",
    "        L_stance = (ltf[1:].reset_index(drop=True) - lhs.reset_index(drop=True)).dropna()\n",
    "        R_swing = (rhs - rtf).dropna()\n",
    "        R_stance = (rtf[1:].reset_index(drop=True) - rhs.reset_index(drop=True)).dropna()\n",
    "        L_steptime = (lhs - rhs).dropna()\n",
    "        R_steptime = (rhs[1:].reset_index(drop=True) - lhs.reset_index(drop=True)).dropna()\n",
    "\n",
    "        # Combine phases\n",
    "        swing = np.concatenate([L_swing, R_swing])\n",
    "        stance = np.concatenate([L_stance, R_stance])\n",
    "        steptime = np.concatenate([L_steptime, R_steptime])\n",
    "        double = (rtf[1:].reset_index(drop=True) - lhs.reset_index(drop=True)).dropna().reset_index(drop=True)\n",
    "        double += (ltf - rhs).reset_index(drop=True).dropna().reset_index(drop=True)\n",
    "\n",
    "        # Averages (temporal)\n",
    "        avg_swing_left_list.append(np.mean(L_swing)/fps)\n",
    "        avg_swing_right_list.append(np.mean(R_swing)/fps)\n",
    "        avg_stance_left_list.append(np.mean(L_stance)/fps)\n",
    "        avg_stance_right_list.append(np.mean(R_stance)/fps)\n",
    "        avg_steptime_left_list.append(np.mean(L_steptime)/fps)\n",
    "        avg_steptime_right_list.append(np.mean(R_steptime)/fps)\n",
    "        avg_swing_list.append(np.mean(swing)/fps)\n",
    "        avg_stance_list.append(np.mean(stance)/fps)\n",
    "        avg_double_list.append(np.mean(double)/fps)\n",
    "        avg_steptime = np.mean(steptime)/fps\n",
    "        avg_steptime_list.append(avg_steptime)\n",
    "        cadence_list.append(60 / avg_steptime)\n",
    "\n",
    "        # Load keypoints\n",
    "        npy_file_path = os.path.join(keypoints_dir, files[m].split(\".\")[0] + '.npy')\n",
    "        keypoints = np.load(npy_file_path)\n",
    "        keypoints = keypoints[:, expected_order_idx] / 1000.0\n",
    "        keypoints[:, :, 1] *= -1  # Flip Y axis\n",
    "        z_hip = keypoints[:, 0, 2]\n",
    "\n",
    "        # Step lengths\n",
    "        lhs_int, rhs_int = lhs.dropna().astype(int), rhs.dropna().astype(int)\n",
    "        if (np.isnan(rhs.iloc[0])) and (not np.isnan(lhs.iloc[0])):\n",
    "            min_len = min(len(lhs_int)-1, len(rhs_int))\n",
    "            step_length_left = abs(z_hip[lhs_int.iloc[1:(min_len + 1)]] - z_hip[rhs_int.iloc[:min_len]])\n",
    "            step_length_right = abs(z_hip[rhs_int.iloc[:min_len]] - z_hip[lhs_int.iloc[:min_len]])\n",
    "        else:\n",
    "            min_len = min(len(lhs_int), len(rhs_int)-1)\n",
    "            step_length_left = abs(z_hip[lhs_int.iloc[:min_len]] - z_hip[rhs_int.iloc[:min_len]])\n",
    "            step_length_right = abs(z_hip[rhs_int.iloc[1:(min_len + 1)]] - z_hip[lhs_int.iloc[:min_len]])\n",
    "\n",
    "        step_length = np.concatenate([step_length_left, step_length_right])\n",
    "        sort_heelstrike = sorted(lhs_int.tolist() + rhs_int.tolist())\n",
    "        avg_velocity = abs((z_hip[sort_heelstrike[-1]] - z_hip[sort_heelstrike[0]]) / \n",
    "                           (sort_heelstrike[-1] - sort_heelstrike[0]) * fps)\n",
    "\n",
    "        # Arm swing symmetry\n",
    "        keypoints_centered = keypoints - keypoints[:, 0:1]\n",
    "        correlation = np.corrcoef(\n",
    "            keypoints_centered[:, 15, 2],  # lelb\n",
    "            keypoints_centered[:, 12, 2]   # relb\n",
    "        )[0, 1]\n",
    "\n",
    "        # Append spatial metrics\n",
    "        avg_step_length_left_list.append(np.mean(step_length_left))\n",
    "        avg_step_length_right_list.append(np.mean(step_length_right))\n",
    "        avg_steplength_list.append(np.mean(step_length))\n",
    "        avg_velocity_list.append(avg_velocity)\n",
    "        correlation_list.append(correlation)\n",
    "        trial_name_list.append(files[m].split('.')[0])\n",
    "\n",
    "    # Results to DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        \"trial_name\": trial_name_list,\n",
    "        \"avg_stancetime\": avg_stance_list,\n",
    "        \"avg_swingtime\": avg_swing_list,\n",
    "        \"avg_doublesupporttime\": avg_double_list,\n",
    "        \"avg_steptime\": avg_steptime_list,\n",
    "        \"avg_steplength\": avg_steplength_list,\n",
    "        \"avg_velocity\": avg_velocity_list,\n",
    "        \"avg_cadence\": cadence_list,\n",
    "        \"avg_stancetime_left\": avg_stance_left_list,\n",
    "        \"avg_stancetime_right\": avg_stance_right_list,\n",
    "        \"avg_swingtime_left\": avg_swing_left_list,\n",
    "        \"avg_swingtime_right\": avg_swing_right_list,\n",
    "        \"avg_steptime_left\": avg_steptime_left_list,\n",
    "        \"avg_steptime_right\": avg_steptime_right_list,\n",
    "        \"avg_steplength_left\": avg_step_length_left_list,\n",
    "        \"avg_steplength_right\": avg_step_length_right_list,\n",
    "        \"arm_swing_corr\": correlation_list\n",
    "    })\n",
    "\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73b1b428-ef3a-4afe-920a-fecfb620c369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T1.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T2.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T3.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T4.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T5.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_001_T6.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T1.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T2.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T3.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T4.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T5.mp4\n",
      "Mirrored video saved as ../Downloads/Results/mirror_video/GEN_002_T6.mp4\n",
      "Step 1: Extracting pose keypoints from video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T1.mp4: 50it [01:07,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T1.mp4 and saved keypoints to GEN_001_T1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T2.mp4: 14it [00:09,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Skipping GEN_001_T2.mp4 due to multiple people detected.\n",
      "Skipping GEN_001_T2.mp4 — one or more frames have no detected person.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T3.mp4: 39it [00:33,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T3.mp4 and saved keypoints to GEN_001_T3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T4.mp4: 45it [00:42,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Skipping GEN_001_T4.mp4 due to multiple people detected.\n",
      "Processed GEN_001_T4.mp4 and saved keypoints to GEN_001_T4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T5.mp4: 48it [00:44,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T5.mp4 and saved keypoints to GEN_001_T5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T6.mp4: 49it [00:45,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T6.mp4 and saved keypoints to GEN_001_T6.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T1.mp4: 42it [00:37,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T1.mp4 and saved keypoints to GEN_002_T1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T2.mp4: 42it [00:36,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T2.mp4 and saved keypoints to GEN_002_T2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T3.mp4: 45it [00:42,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T3.mp4 and saved keypoints to GEN_002_T3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T4.mp4: 42it [00:37,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T4.mp4 and saved keypoints to GEN_002_T4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T5.mp4: 37it [00:31,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T5.mp4 and saved keypoints to GEN_002_T5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T6.mp4: 42it [00:37,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T6.mp4 and saved keypoints to GEN_002_T6.npy\n",
      "Step 2: Running Gait Transformer model on extracted keypoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_001_T1_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_001_T3_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_001_T4_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_001_T5_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_001_T6_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T1_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T2_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T3_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T4_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T5_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/JSON/GEN_002_T6_gait_events_L60.json\n",
      "Step 3: Arranging gait events and exporting to Excel...\n",
      "Saved arranged gait events to ../Downloads/Results/gaitevents_video.xlsx\n",
      "✅ Full gait processing pipeline complete.\n",
      "Step 1: Extracting pose keypoints from video files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T1.mp4: 50it [00:48,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T1.mp4 and saved keypoints to GEN_001_T1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T2.mp4: 50it [00:46,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T2.mp4 and saved keypoints to GEN_001_T2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T3.mp4: 39it [00:33,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T3.mp4 and saved keypoints to GEN_001_T3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T4.mp4: 12it [00:08,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Skipping GEN_001_T4.mp4 due to multiple people detected.\n",
      "Skipping GEN_001_T4.mp4 — one or more frames have no detected person.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T5.mp4: 48it [00:45,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_001_T5.mp4 and saved keypoints to GEN_001_T5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_001_T6.mp4: 13it [00:08,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Skipping GEN_001_T6.mp4 due to multiple people detected.\n",
      "Skipping GEN_001_T6.mp4 — one or more frames have no detected person.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T1.mp4: 42it [00:37,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T1.mp4 and saved keypoints to GEN_002_T1.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T2.mp4: 42it [00:36,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T2.mp4 and saved keypoints to GEN_002_T2.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T3.mp4: 45it [00:41,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T3.mp4 and saved keypoints to GEN_002_T3.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T4.mp4: 42it [00:36,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T4.mp4 and saved keypoints to GEN_002_T4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T5.mp4: 37it [00:32,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T5.mp4 and saved keypoints to GEN_002_T5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GEN_002_T6.mp4: 42it [00:35,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed GEN_002_T6.mp4 and saved keypoints to GEN_002_T6.npy\n",
      "Step 2: Running Gait Transformer model on extracted keypoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_001_T1_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_001_T2_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_001_T3_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_001_T5_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T1_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T2_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T3_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T4_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T5_gait_events_L60.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  9.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../Downloads/Results/mirror_JSON/GEN_002_T6_gait_events_L60.json\n",
      "Step 3: Arranging gait events and exporting to Excel...\n",
      "Saved arranged gait events to ../Downloads/Results/gaitevents_mirror.xlsx\n",
      "✅ Full gait processing pipeline complete.\n",
      "Excel file 'feature_results.xlsx' has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Mirror Videos \n",
    "height_cm = 150 \n",
    "# Set up directories\n",
    "input_dir = \"../Downloads/AFTERTRIM\"    \n",
    "Output_dir = os.path.join(os.path.dirname(input_dir), \"Results\")\n",
    "output_dir = os.path.join(os.path.dirname(input_dir), \"Results\", \"mirror_video\")\n",
    "# Make sure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "# List all .mp4 files in input folder\n",
    "file_names = [f for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
    "file_names.sort(key=extract_parts)\n",
    "\n",
    "# Track already processed files\n",
    "processed_files = {os.path.splitext(f)[0] for f in os.listdir(output_dir) if f.endswith(\".mp4\")}\n",
    "\n",
    "# Loop through and mirror videos\n",
    "for file_name in file_names:\n",
    "    video_name = os.path.splitext(file_name)[0]\n",
    "    if video_name in processed_files:\n",
    "        print(f\"Skipping {file_name} — already processed.\")\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, file_name)\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    mirror_video(input_path, output_path)\n",
    "\n",
    "\n",
    "# Run video processing \n",
    "run_full_gait_processing_pipeline(\n",
    "    video_directory=input_dir,\n",
    "    keypoints_output_dir=os.path.join(Output_dir, \"keypoints\"),\n",
    "    gait_json_output_dir=os.path.join(Output_dir, \"JSON\"),\n",
    "    final_excel_path=os.path.join(Output_dir, \"gaitevents_video.xlsx\"),\n",
    "    model=model,\n",
    "    skeleton=skeleton,\n",
    "    video_reader=video_reader,\n",
    "    transformer_model=transformer_model,\n",
    "    height_mm=height_cm * 10,\n",
    "    expected_order_idx=expected_order_idx,\n",
    "    extract_parts=extract_parts,\n",
    "    convert_to_int=convert_to_int,\n",
    "    shift_invalid_rows=shift_invalid_rows\n",
    ")\n",
    "\n",
    "\n",
    "run_full_gait_processing_pipeline(\n",
    "    video_directory=output_dir,\n",
    "    keypoints_output_dir=os.path.join(Output_dir, \"mirror_keypoints\"),\n",
    "    gait_json_output_dir=os.path.join(Output_dir, \"mirror_JSON\"),\n",
    "    final_excel_path=os.path.join(Output_dir, \"gaitevents_mirror.xlsx\"),\n",
    "    model=model,\n",
    "    skeleton=skeleton,\n",
    "    video_reader=video_reader,\n",
    "    transformer_model=transformer_model,\n",
    "    height_mm=height_cm * 10,\n",
    "    expected_order_idx=expected_order_idx,\n",
    "    extract_parts=extract_parts,\n",
    "    convert_to_int=convert_to_int,\n",
    "    shift_invalid_rows=shift_invalid_rows\n",
    ")\n",
    "\n",
    "\n",
    "# Run feature extraction \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load your file\n",
    "df_video = pd.read_excel(os.path.join(Output_dir, \"gaitevents_video.xlsx\"))\n",
    "df_mirror = pd.read_excel(os.path.join(Output_dir, \"gaitevents_mirror.xlsx\"))\n",
    "\n",
    "# filter \n",
    "df_video_filtered = filter_numeric_columns(df_video, threshold=12)\n",
    "df_mirror_filtered = filter_numeric_columns(df_mirror, threshold=12)\n",
    "\n",
    "\n",
    "df_video_results = analyze_gait_video_features(\n",
    "    df_video=df_video_filtered,\n",
    "    keypoints_dir=os.path.join(Output_dir, \"keypoints\"),\n",
    "    expected_order_idx=expected_order_idx,\n",
    "    extract_parts=extract_parts\n",
    ")\n",
    "\n",
    "\n",
    "df_mirror_results = analyze_gait_video_features(\n",
    "    df_video=df_mirror_filtered,\n",
    "    keypoints_dir=os.path.join(Output_dir, \"mirror_keypoints\"),\n",
    "    expected_order_idx=expected_order_idx,\n",
    "    extract_parts=extract_parts\n",
    ")\n",
    "\n",
    "\n",
    "## swap mirror file columns \n",
    "# Get the current column names\n",
    "columns = df_mirror_results.columns.tolist()\n",
    "# Define the index pairs to swap\n",
    "swap_pairs = [(8,9), (10, 11), (12, 13), (14,15)]\n",
    "# Swap the column names\n",
    "for i, j in swap_pairs:\n",
    "    columns[i], columns[j] = columns[j], columns[i]\n",
    "# Assign the new column names back\n",
    "df_mirror_results.columns = columns\n",
    "\n",
    "# average \n",
    "# Merge on trial name (assumes the first column is trial name)\n",
    "merged = pd.merge(df_video_results, df_mirror_results, on='trial_name', suffixes=('_video', '_mirror'))\n",
    "# Identify numeric columns to average (exclude 'trial_name')\n",
    "numeric_cols = df_video_results.select_dtypes(include='number').columns\n",
    "# Create a new DataFrame for averaged results\n",
    "df_avg = pd.DataFrame()\n",
    "df_avg['trial_name'] = merged['trial_name']\n",
    "# Average each numeric column\n",
    "for col in numeric_cols:\n",
    "    col_video = f\"{col}_video\"\n",
    "    col_mirror = f\"{col}_mirror\"\n",
    "    df_avg[col] = (merged[col_video] + merged[col_mirror]) / 2\n",
    "\n",
    "\n",
    "# Save to Excel\n",
    "df_avg.to_excel(os.path.join(Output_dir, \"feature_results.xlsx\"), index=False)\n",
    "print(\"Excel file 'feature_results.xlsx' has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f14942a3-e37a-481a-8005-e77d788f7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_name</th>\n",
       "      <th>avg_stancetime</th>\n",
       "      <th>avg_swingtime</th>\n",
       "      <th>avg_doublesupporttime</th>\n",
       "      <th>avg_steptime</th>\n",
       "      <th>avg_steplength</th>\n",
       "      <th>avg_velocity</th>\n",
       "      <th>avg_cadence</th>\n",
       "      <th>avg_stancetime_left</th>\n",
       "      <th>avg_stancetime_right</th>\n",
       "      <th>avg_swingtime_left</th>\n",
       "      <th>avg_swingtime_right</th>\n",
       "      <th>avg_steptime_left</th>\n",
       "      <th>avg_steptime_right</th>\n",
       "      <th>avg_steplength_left</th>\n",
       "      <th>avg_steplength_right</th>\n",
       "      <th>arm_swing_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEN_001_T1</td>\n",
       "      <td>0.671212</td>\n",
       "      <td>0.398485</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.534848</td>\n",
       "      <td>1.06192</td>\n",
       "      <td>1.948827</td>\n",
       "      <td>112.181303</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>1.21312</td>\n",
       "      <td>0.91072</td>\n",
       "      <td>-0.796860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEN_001_T3</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.05390</td>\n",
       "      <td>1.976063</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>1.10820</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>-0.853089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEN_001_T4</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.398333</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.94888</td>\n",
       "      <td>1.762625</td>\n",
       "      <td>111.455108</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.75904</td>\n",
       "      <td>1.13872</td>\n",
       "      <td>-0.597728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEN_001_T5</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>0.401515</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.07548</td>\n",
       "      <td>2.031477</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>1.24680</td>\n",
       "      <td>0.90416</td>\n",
       "      <td>-0.892876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEN_001_T6</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.398485</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>1.07608</td>\n",
       "      <td>1.940204</td>\n",
       "      <td>111.864407</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>1.06672</td>\n",
       "      <td>1.08544</td>\n",
       "      <td>-0.737881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEN_002_T1</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>1.03805</td>\n",
       "      <td>1.909589</td>\n",
       "      <td>107.284768</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>1.11850</td>\n",
       "      <td>0.95760</td>\n",
       "      <td>-0.797497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEN_002_T2</td>\n",
       "      <td>0.687037</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>1.12290</td>\n",
       "      <td>2.003108</td>\n",
       "      <td>109.459459</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.07500</td>\n",
       "      <td>1.17080</td>\n",
       "      <td>-0.722773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEN_002_T3</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.276667</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>1.04136</td>\n",
       "      <td>1.910752</td>\n",
       "      <td>110.091743</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.13296</td>\n",
       "      <td>0.94976</td>\n",
       "      <td>-0.829507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEN_002_T4</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.409259</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.06285</td>\n",
       "      <td>1.932455</td>\n",
       "      <td>109.090909</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>1.11810</td>\n",
       "      <td>1.00760</td>\n",
       "      <td>-0.764689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEN_002_T5</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>1.09120</td>\n",
       "      <td>1.976513</td>\n",
       "      <td>108.679245</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.370833</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>1.23740</td>\n",
       "      <td>0.94500</td>\n",
       "      <td>-0.905068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEN_002_T6</td>\n",
       "      <td>0.692593</td>\n",
       "      <td>0.409259</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.551852</td>\n",
       "      <td>1.10810</td>\n",
       "      <td>1.951248</td>\n",
       "      <td>108.724832</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.13060</td>\n",
       "      <td>1.08560</td>\n",
       "      <td>-0.780977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial_name  avg_stancetime  avg_swingtime  avg_doublesupporttime  \\\n",
       "0   GEN_001_T1        0.671212       0.398485               0.275000   \n",
       "1   GEN_001_T3        0.670833       0.400000               0.270833   \n",
       "2   GEN_001_T4        0.680000       0.398333               0.280000   \n",
       "3   GEN_001_T5        0.665152       0.401515               0.263889   \n",
       "4   GEN_001_T6        0.674242       0.398485               0.277778   \n",
       "5   GEN_002_T1        0.703704       0.411111               0.293333   \n",
       "6   GEN_002_T2        0.687037       0.407407               0.283333   \n",
       "7   GEN_002_T3        0.685000       0.406667               0.276667   \n",
       "8   GEN_002_T4        0.693750       0.409259               0.287500   \n",
       "9   GEN_002_T5        0.693750       0.400000               0.283333   \n",
       "10  GEN_002_T6        0.692593       0.409259               0.286667   \n",
       "\n",
       "    avg_steptime  avg_steplength  avg_velocity  avg_cadence  \\\n",
       "0       0.534848         1.06192      1.948827   112.181303   \n",
       "1       0.533333         1.05390      1.976063   112.500000   \n",
       "2       0.538333         0.94888      1.762625   111.455108   \n",
       "3       0.533333         1.07548      2.031477   112.500000   \n",
       "4       0.536364         1.07608      1.940204   111.864407   \n",
       "5       0.559259         1.03805      1.909589   107.284768   \n",
       "6       0.548148         1.12290      2.003108   109.459459   \n",
       "7       0.545000         1.04136      1.910752   110.091743   \n",
       "8       0.550000         1.06285      1.932455   109.090909   \n",
       "9       0.552083         1.09120      1.976513   108.679245   \n",
       "10      0.551852         1.10810      1.951248   108.724832   \n",
       "\n",
       "    avg_stancetime_left  avg_stancetime_right  avg_swingtime_left  \\\n",
       "0              0.652778              0.693333            0.423333   \n",
       "1              0.637500              0.704167            0.426667   \n",
       "2              0.690000              0.670000            0.390000   \n",
       "3              0.636667              0.688889            0.425000   \n",
       "4              0.670000              0.677778            0.400000   \n",
       "5              0.658333              0.740000            0.446667   \n",
       "6              0.675000              0.696667            0.413333   \n",
       "7              0.656667              0.713333            0.436667   \n",
       "8              0.687500              0.700000            0.416667   \n",
       "9              0.654167              0.733333            0.450000   \n",
       "10             0.687500              0.696667            0.410000   \n",
       "\n",
       "    avg_swingtime_right  avg_steptime_left  avg_steptime_right  \\\n",
       "0              0.377778           0.570000            0.505556   \n",
       "1              0.366667           0.575000            0.491667   \n",
       "2              0.406667           0.526667            0.550000   \n",
       "3              0.373333           0.563889            0.496667   \n",
       "4              0.396667           0.541667            0.530000   \n",
       "5              0.366667           0.613333            0.491667   \n",
       "6              0.400000           0.560000            0.533333   \n",
       "7              0.376667           0.590000            0.500000   \n",
       "8              0.400000           0.562500            0.537500   \n",
       "9              0.370833           0.608333            0.495833   \n",
       "10             0.408333           0.560000            0.541667   \n",
       "\n",
       "    avg_steplength_left  avg_steplength_right  arm_swing_corr  \n",
       "0               1.21312               0.91072       -0.796860  \n",
       "1               1.10820               0.99960       -0.853089  \n",
       "2               0.75904               1.13872       -0.597728  \n",
       "3               1.24680               0.90416       -0.892876  \n",
       "4               1.06672               1.08544       -0.737881  \n",
       "5               1.11850               0.95760       -0.797497  \n",
       "6               1.07500               1.17080       -0.722773  \n",
       "7               1.13296               0.94976       -0.829507  \n",
       "8               1.11810               1.00760       -0.764689  \n",
       "9               1.23740               0.94500       -0.905068  \n",
       "10              1.13060               1.08560       -0.780977  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e5e46c3-68b3-4e48-98cd-9cd85d100f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_name</th>\n",
       "      <th>avg_stancetime</th>\n",
       "      <th>avg_swingtime</th>\n",
       "      <th>avg_doublesupporttime</th>\n",
       "      <th>avg_steptime</th>\n",
       "      <th>avg_steplength</th>\n",
       "      <th>avg_velocity</th>\n",
       "      <th>avg_cadence</th>\n",
       "      <th>avg_stancetime_right</th>\n",
       "      <th>avg_stancetime_left</th>\n",
       "      <th>avg_swingtime_right</th>\n",
       "      <th>avg_swingtime_left</th>\n",
       "      <th>avg_steptime_right</th>\n",
       "      <th>avg_steptime_left</th>\n",
       "      <th>avg_steplength_right</th>\n",
       "      <th>avg_steplength_left</th>\n",
       "      <th>arm_swing_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEN_001_T1</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.269444</td>\n",
       "      <td>0.543939</td>\n",
       "      <td>1.09420</td>\n",
       "      <td>1.953092</td>\n",
       "      <td>110.306407</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>1.02328</td>\n",
       "      <td>1.165120</td>\n",
       "      <td>-0.847245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEN_001_T2</td>\n",
       "      <td>0.680303</td>\n",
       "      <td>0.403030</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.99824</td>\n",
       "      <td>1.872874</td>\n",
       "      <td>110.924370</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>1.05840</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>-0.631759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEN_001_T3</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>1.07400</td>\n",
       "      <td>2.029606</td>\n",
       "      <td>113.385827</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>1.21520</td>\n",
       "      <td>0.932800</td>\n",
       "      <td>-0.860447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEN_001_T5</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.395455</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>1.07944</td>\n",
       "      <td>2.057241</td>\n",
       "      <td>113.793103</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.369444</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>1.05072</td>\n",
       "      <td>1.108160</td>\n",
       "      <td>-0.908155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEN_002_T1</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.411111</td>\n",
       "      <td>0.276667</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>1.03300</td>\n",
       "      <td>1.911892</td>\n",
       "      <td>109.459459</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.445833</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.07600</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>-0.823180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEN_002_T2</td>\n",
       "      <td>0.681481</td>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>1.09190</td>\n",
       "      <td>1.981773</td>\n",
       "      <td>111.340206</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>1.32840</td>\n",
       "      <td>0.855400</td>\n",
       "      <td>-0.749634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEN_002_T3</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.411667</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>1.05668</td>\n",
       "      <td>1.927076</td>\n",
       "      <td>109.422492</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.07312</td>\n",
       "      <td>1.040241</td>\n",
       "      <td>-0.853071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEN_002_T4</td>\n",
       "      <td>0.690741</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>1.08390</td>\n",
       "      <td>1.939837</td>\n",
       "      <td>110.204082</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>1.25800</td>\n",
       "      <td>0.909800</td>\n",
       "      <td>-0.775232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEN_002_T5</td>\n",
       "      <td>0.689583</td>\n",
       "      <td>0.410417</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.09630</td>\n",
       "      <td>1.993273</td>\n",
       "      <td>109.090909</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>1.02060</td>\n",
       "      <td>1.172000</td>\n",
       "      <td>-0.911028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEN_002_T6</td>\n",
       "      <td>0.687037</td>\n",
       "      <td>0.401852</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.542593</td>\n",
       "      <td>1.09230</td>\n",
       "      <td>1.968901</td>\n",
       "      <td>110.580205</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.16780</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>-0.790548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_name  avg_stancetime  avg_swingtime  avg_doublesupporttime  \\\n",
       "0  GEN_001_T1        0.675758       0.409091               0.269444   \n",
       "1  GEN_001_T2        0.680303       0.403030               0.277778   \n",
       "2  GEN_001_T3        0.656250       0.400000               0.250000   \n",
       "3  GEN_001_T5        0.659091       0.395455               0.263889   \n",
       "4  GEN_002_T1        0.685185       0.411111               0.276667   \n",
       "5  GEN_002_T2        0.681481       0.398148               0.283333   \n",
       "6  GEN_002_T3        0.685000       0.411667               0.273333   \n",
       "7  GEN_002_T4        0.690741       0.400000               0.293333   \n",
       "8  GEN_002_T5        0.689583       0.410417               0.279167   \n",
       "9  GEN_002_T6        0.687037       0.401852               0.290000   \n",
       "\n",
       "   avg_steptime  avg_steplength  avg_velocity  avg_cadence  \\\n",
       "0      0.543939         1.09420      1.953092   110.306407   \n",
       "1      0.540909         0.99824      1.872874   110.924370   \n",
       "2      0.529167         1.07400      2.029606   113.385827   \n",
       "3      0.527273         1.07944      2.057241   113.793103   \n",
       "4      0.548148         1.03300      1.911892   109.459459   \n",
       "5      0.538889         1.09190      1.981773   111.340206   \n",
       "6      0.548333         1.05668      1.927076   109.422492   \n",
       "7      0.544444         1.08390      1.939837   110.204082   \n",
       "8      0.550000         1.09630      1.993273   109.090909   \n",
       "9      0.542593         1.09230      1.968901   110.580205   \n",
       "\n",
       "   avg_stancetime_right  avg_stancetime_left  avg_swingtime_right  \\\n",
       "0              0.633333             0.711111             0.441667   \n",
       "1              0.672222             0.690000             0.413333   \n",
       "2              0.629167             0.683333             0.433333   \n",
       "3              0.633333             0.690000             0.426667   \n",
       "4              0.660000             0.716667             0.445833   \n",
       "5              0.680000             0.683333             0.400000   \n",
       "6              0.653333             0.716667             0.443333   \n",
       "7              0.690000             0.691667             0.404167   \n",
       "8              0.670833             0.708333             0.429167   \n",
       "9              0.683333             0.691667             0.412500   \n",
       "\n",
       "   avg_swingtime_left  avg_steptime_right  avg_steptime_left  \\\n",
       "0            0.370000            0.586111           0.493333   \n",
       "1            0.394444            0.553333           0.530556   \n",
       "2            0.373333            0.566667           0.491667   \n",
       "3            0.369444            0.566667           0.494444   \n",
       "4            0.383333            0.583333           0.520000   \n",
       "5            0.396667            0.541667           0.536667   \n",
       "6            0.380000            0.586667           0.510000   \n",
       "7            0.396667            0.550000           0.540000   \n",
       "8            0.391667            0.575000           0.525000   \n",
       "9            0.393333            0.554167           0.533333   \n",
       "\n",
       "   avg_steplength_right  avg_steplength_left  arm_swing_corr  \n",
       "0               1.02328             1.165120       -0.847245  \n",
       "1               1.05840             0.938080       -0.631759  \n",
       "2               1.21520             0.932800       -0.860447  \n",
       "3               1.05072             1.108160       -0.908155  \n",
       "4               1.07600             0.990000       -0.823180  \n",
       "5               1.32840             0.855400       -0.749634  \n",
       "6               1.07312             1.040241       -0.853071  \n",
       "7               1.25800             0.909800       -0.775232  \n",
       "8               1.02060             1.172000       -0.911028  \n",
       "9               1.16780             1.016800       -0.790548  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mirror_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7d0de40-a878-4a83-b022-b2c98426c97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadecce-fd0a-4b45-987d-1dddbb70a0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
